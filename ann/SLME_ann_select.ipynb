{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c21c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2422949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape is (390, 57) ; y_train's shape is (390,)\n",
      "X_test's shape is (98, 57) ; y_test's shape is (98,)\n"
     ]
    }
   ],
   "source": [
    "#读数据标准化划分数据集\n",
    "df = pd.read_csv('../my_data.csv')\n",
    "X = df.iloc[:, 1:58]\n",
    "Y = df.iloc[:, 58:]\n",
    "Y=Y['SLME @ 5um']\n",
    "names=df.columns\n",
    "names=['SHAP value of '+x for x in names]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "print(\"X_train's shape is\", X_train.shape,\"; y_train's shape is\", y_train.shape)\n",
    "print(\"X_test's shape is\", X_test.shape,\"; y_test's shape is\",y_test.shape)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_stand = scaler.transform(X_train)\n",
    "X_test_stand = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf2295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],  # 隐藏层神经元数量和层数的组合\n",
    "    'activation': ['relu', 'tanh'],  # 激活函数选项\n",
    "    'solver': ['adam', 'sgd'],  # 优化器选项\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # 正则化参数选项\n",
    "    'learning_rate': ['constant', 'adaptive'],  # 学习率策略选项\n",
    "    'max_iter': [200, 300, 400],  # 最大迭代次数\n",
    "    'batch_size': [16, 32, 64],  # 批量大小\n",
    "    'momentum': [0.9, 0.95, 0.99],  # 动量参数\n",
    "    'early_stopping': [True, False],  # 提前停止\n",
    "    'n_iter_no_change': [5, 10, 15],  # 没有改变迭代次数\n",
    "    'shuffle': [True, False],  # 是否打乱数据\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88190899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 31104 candidates, totalling 93312 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2232 fits failed out of a total of 93312.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1944 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 435, in _fit\n",
      "    incremental,\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 661, in _fit_stochastic\n",
      "    self._update_no_improvement_count(early_stopping, X_val, y_val)\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 709, in _update_no_improvement_count\n",
      "    self.validation_scores_.append(self.score(X_val, y_val))\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\base.py\", line 706, in score\n",
      "    return r2_score(y, y_pred, sample_weight=sample_weight)\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 790, in r2_score\n",
      "    y_true, y_pred, multioutput\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 96, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 800, in check_array\n",
      "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 116, in _assert_all_finite\n",
      "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "288 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 752, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 435, in _fit\n",
      "    incremental,\n",
      "  File \"D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 703, in _fit_stochastic\n",
      "    self.coefs_ = self._best_coefs\n",
      "AttributeError: 'MLPRegressor' object has no attribute '_best_coefs'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [-3.37845080e+00 -6.26238161e+02 -2.09711208e+00 ... -6.29306385e-02\n",
      " -5.03783804e-02 -5.68416535e-02]\n",
      "  category=UserWarning,\n",
      "D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:978: RuntimeWarning: invalid value encountered in subtract\n",
      "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n",
      "D:\\App\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the train scores are non-finite: [-2.71492395e+00 -6.26214427e+02 -1.61885807e+00 ... -6.35711655e-02\n",
      " -3.56538333e-02 -5.47559986e-02]\n",
      "  category=UserWarning,\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0           1.283375      0.787529         0.006189        0.001884   \n",
      "1           1.988252      0.114636         0.003180        0.000255   \n",
      "2           1.955132      0.100465         0.003179        0.000245   \n",
      "3           1.471471      0.167930         0.003844        0.000616   \n",
      "4           2.161271      0.073122         0.004018        0.001098   \n",
      "...              ...           ...              ...             ...   \n",
      "31099       0.473759      0.032537         0.003523        0.000006   \n",
      "31100       0.563441      0.041520         0.002839        0.001029   \n",
      "31101       0.532473      0.037133         0.002171        0.000238   \n",
      "31102       0.336597      0.032798         0.002338        0.000470   \n",
      "31103       0.451531      0.033796         0.002334        0.000469   \n",
      "\n",
      "      param_activation param_alpha param_batch_size param_early_stopping  \\\n",
      "0                 relu      0.0001               16                 True   \n",
      "1                 relu      0.0001               16                 True   \n",
      "2                 relu      0.0001               16                 True   \n",
      "3                 relu      0.0001               16                 True   \n",
      "4                 relu      0.0001               16                 True   \n",
      "...                ...         ...              ...                  ...   \n",
      "31099             tanh        0.01               64                False   \n",
      "31100             tanh        0.01               64                False   \n",
      "31101             tanh        0.01               64                False   \n",
      "31102             tanh        0.01               64                False   \n",
      "31103             tanh        0.01               64                False   \n",
      "\n",
      "      param_hidden_layer_sizes param_learning_rate  ... split1_test_score  \\\n",
      "0                        (50,)            constant  ...         -5.438168   \n",
      "1                        (50,)            constant  ...        -21.708965   \n",
      "2                        (50,)            constant  ...         -1.944485   \n",
      "3                        (50,)            constant  ...         -0.446047   \n",
      "4                        (50,)            constant  ...         -1.969119   \n",
      "...                        ...                 ...  ...               ...   \n",
      "31099                (100, 50)            adaptive  ...         -0.077963   \n",
      "31100                (100, 50)            adaptive  ...         -0.051801   \n",
      "31101                (100, 50)            adaptive  ...         -0.053115   \n",
      "31102                (100, 50)            adaptive  ...         -0.055378   \n",
      "31103                (100, 50)            adaptive  ...         -0.056537   \n",
      "\n",
      "      split2_test_score mean_test_score std_test_score rank_test_score  \\\n",
      "0             -2.307197       -3.378451       1.456832           22516   \n",
      "1          -1856.924719     -626.238161     870.271604           23598   \n",
      "2             -2.286575       -2.097112       0.142066           19420   \n",
      "3             -0.073681     -315.163343     445.340797           23560   \n",
      "4             -2.113805       -2.059614       0.064405           19348   \n",
      "...                 ...             ...            ...             ...   \n",
      "31099         -0.062919       -0.069466       0.006294            6827   \n",
      "31100         -0.044759       -0.050537       0.004295            1113   \n",
      "31101         -0.082472       -0.062931       0.013818            5024   \n",
      "31102         -0.048640       -0.050378       0.003589            1005   \n",
      "31103         -0.053236       -0.056842       0.003076            3352   \n",
      "\n",
      "      split0_train_score  split1_train_score  split2_train_score  \\\n",
      "0              -1.952050           -4.453044           -1.739677   \n",
      "1              -0.074321          -21.655525        -1856.913435   \n",
      "2              -1.560585           -1.537266           -1.758723   \n",
      "3            -944.985578           -0.076503           -0.077445   \n",
      "4              -1.535638           -1.568180           -1.627694   \n",
      "...                  ...                 ...                 ...   \n",
      "31099          -0.062454           -0.066872           -0.071775   \n",
      "31100          -0.050341           -0.044833           -0.039320   \n",
      "31101          -0.049594           -0.060801           -0.080319   \n",
      "31102          -0.033025           -0.036373           -0.037563   \n",
      "31103          -0.054785           -0.056657           -0.052826   \n",
      "\n",
      "       mean_train_score  std_train_score  \n",
      "0             -2.714924         1.232091  \n",
      "1           -626.214427       870.280213  \n",
      "2             -1.618858         0.099357  \n",
      "3           -315.046508       445.434188  \n",
      "4             -1.577171         0.038116  \n",
      "...                 ...              ...  \n",
      "31099         -0.067034         0.003807  \n",
      "31100         -0.044831         0.004499  \n",
      "31101         -0.063571         0.012695  \n",
      "31102         -0.035654         0.001921  \n",
      "31103         -0.054756         0.001564  \n",
      "\n",
      "[31104 rows x 27 columns]\n",
      "{'activation': 'tanh', 'alpha': 0.01, 'batch_size': 16, 'early_stopping': False, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'max_iter': 300, 'momentum': 0.9, 'n_iter_no_change': 10, 'shuffle': False, 'solver': 'adam'}\n",
      "make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
      "-0.03881743607246587\n"
     ]
    }
   ],
   "source": [
    "ann = MLPRegressor(random_state=10)\n",
    "model = GridSearchCV(estimator =ann,scoring='neg_root_mean_squared_error', \n",
    "                     param_grid = param_grid,cv=3, verbose=3,n_jobs =-1,return_train_score=True)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.cv_results_)\n",
    "dfresult=pd.DataFrame(model.cv_results_)\n",
    "dfresult.to_csv('SLME_ANN13y32.csv')\n",
    "print(dfresult)\n",
    "print(model.best_params_)\n",
    "print(model.scorer_)\n",
    "print(model.best_score_)\n",
    "bestmodel=model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ab148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
